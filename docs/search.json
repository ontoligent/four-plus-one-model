[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The 4+1 Model of Data Science",
    "section": "",
    "text": "Data Science is a complex and evolving field, but most agree that it can be defined as a combination of expertise drawn from three broad areas — computer science and technology, math and statistics, and domain knowledge — with the purpose of extracting knowledge and value from data. Many also associate it with a series of practical activities ranging from the cleaning and “wrangling” of data, to its analysis and use to infer models, to the visual and rhetorical representation of results to stakeholders and decision-makers.\nThis essay proposes a model of data science that is intended to go beyond the laundry-list definitions that dominate the discourse in the field today. Although these are not inaccurate, they do not get at the specific nature of data science or help distinguish it from adjacent fields such as computer science and statistics — fields whose members sometimes claim to already be doing data science. Without a clear understanding of its specific and unique nature, the field is subject to counterproductive turf battles in the academy as well as confusion in the workplace.1\nWe define data science in terms of a multi-part model that represents core areas of expertise in the field and how they are related to each other. These are the areas of value, design, systems, and analytics. A fifth area, practice, integrates the other four in specific contexts. Together, these areas belong to every data science project, even if they are often unconnected and siloed in the academy.\nUnlike traditional academic disciplines, each area of the proposed model is inherently interdisciplinary, bringing together diverse and sometimes contrary perspectives under a common heading. The inherently interdisciplinary and pluralist nature of these areas is a distinctive feature of data science and a key differentiator between it and traditional disciplines.\nThe following describes how this model is derived and provides clues about how to interpret and apply the model to your own situation.\n\n\n\n\n\nIt is increasingly the case that hiring managers in industry understand the role of data scientist differently than the academic programs that produce data scientists. One result of this is the proliferation of terms such as data engineer, machine learning engineer, and applied AI to define areas of work that have historically belonged to data science. Another result is the confusion of data scientist with the roles of data analyst and statistician.↩︎"
  },
  {
    "objectID": "the-four-plus-one-model.html#a-common-theme",
    "href": "the-four-plus-one-model.html#a-common-theme",
    "title": "The Image of the Pipeline",
    "section": "A Common Theme",
    "text": "A Common Theme\nA review of the literature of data science definitions, from sources attempting to define the field explicitly, as well as from self-definitions from adjacent fields such as data analysis and data mining, reveals that most definitions invoke the image of a data processing pipeline — a sequence of actions through which data flows as it moves from the consumption of so-called raw data to production of actionable results. Consumed data may come from a variety of sources — databases or intentional experiments or sensors. Results may be equally various, from the communication of analytical results to stake-holders to the development of a data product for use on the web. For a detailed review of these sources, see the Appendix.\nAn analysis of a representative sample of essays that define a data processing pipeline shows that the various stories consist of elements drawn from a standard sequence of about twelve elements, give or take a few, depending on how one might expand or contract terms. These may signified by a core set of verbs or event types (which narratologists call functions), with the understanding that many synonyms are employed in the examples:\n\nUnderstand\nPlan\nCollect\nStore\nClean\nExplore\nPrepare\nModel\nInterpret\nCommunicate\nDeploy\nReflect\n\nNo one definition includes them all, but some are more comprehensive than others, and different disciplines emphasize different parts.\nFor example, Hayashi’s statistically-oriented definition of data science includes just three phases — design \\([1]\\), collect \\([3]\\), and analyze \\([8, 9]\\) — with an emphasis on the experimental design phase in which data are actually produced through thoughtfully designed experiments (Hayashi 1998).\nMason and Wiggins propose five — obtain \\([3, 4]\\), scrub \\([5]\\), explore \\([6]\\), model \\([8]\\), and interpret \\([9]\\) — which highlights two conditions that define industrial data science, the simultaneous availability of data (one merely obtains it, say through web scraping) and their poor condition relative to analysis, i.e. the need to scrub and wrangle them into usable form (Mason and Wiggins 2010).\nThe CRISP-DM model is the most comprehensive, with seven phases defined (if we include the unnamed but visually depicted function of storage), emphasizing the importance of understanding both the business proposition and data before anything is done with it (Wirth and Hipp 1999). It also modifies the metaphor of the pipeline, representing it as a circular and iterative process. However, unlike Donoho’s similarly comprehensive sequence (implied by the ordering of his six divisions of “greater data science”), it does not include a “meta” phase devoted to reflecting on the process as a whole (Donoho 2017).\nThis twelve-part composite pipeline can be simplified by combining functions that naturally go together, by virtue of the expertise required to carry them out. This reduction yields about seven phases:\n    \\(A\\) understand and plan\n    \\(B\\) collect and store\n    \\(C\\) clean, prepare, and explore\n    \\(D\\) model and interpret\n    \\(E\\) communicate\n    \\(F\\) deploy\n    \\(G\\) reflect\nEach of these may be considered a “chapter” in the story. Note that the number of verbs in each chapter title does not necessarily predict the length of its content. For example, the chapter on “model and interpret” covers a wide range of activities from a variety of perspectives, including classical statistics, machine learning, and computational simulation. It’s a big and complicated chapter, but it is just one chapter among seven, even though many may consider it to be the most important chapter."
  },
  {
    "objectID": "the-four-plus-one-model.html#an-arc-with-four-zones",
    "href": "the-four-plus-one-model.html#an-arc-with-four-zones",
    "title": "The Image of the Pipeline",
    "section": "An Arc with Four Zones",
    "text": "An Arc with Four Zones\n\n\n\nThe Standard Sequence as a Narrative Arc\n\n\nTo be sure, the middle chapter plays a central role in our story. If we think of the story as following a classical “there and back again” structure — a chiasmus pattern like \\(X_1, Y_1, Z, Y_2, X_2\\) — then chapter \\(D\\) is the pivot, while chapters \\(A\\), \\(B\\), and \\(C\\) mirror \\(E\\), \\(F\\), and \\(G\\). Thinking of the story in this way allows us to identify a parallel structure in the pipeline, connecting phases that are usually seen as separate. Specifically, we may visualize the pipeline as an arc, in which chapters in the first half of the pipeline mirror the those of the second half. We may then group chapters by the pairs formed in this way, yielding four zones — \\(A\\) and \\(G\\) belong to zone \\(I\\), \\(B\\) and \\(F\\) to \\(II\\), \\(C\\) and \\(E\\) to \\(III\\), and \\(D\\) to \\(IV\\) — as in the following diagram:\n\n\n\nThe Arc Transposed\n\n\nWith this visualization, we can discern some interesting properties about the data science pipeline that are not obvious in the original sequential image. For one, the arc structure suggests that the two ends of the pipe are not separate; both make direct contact with the external world. The external world — natural or social — from which data are pulled is the same world into which data products are inserted. This insight echoes the CRISP-DM model, which connects \\(A\\) and \\(G\\) (actually \\(F\\)), except that the two ends of the arc model are not directly connected. Instead, they come into contact with — and are separated by — the world in all of its complexity and unpredictability. The relationship between the effects caused by our data products G and the data we pull from the world \\(A\\) is not given but a matter of discovery — and often surprise.\nAt this point, we can explore the unifying themes associated with the four zones in our arc model by transposing the preceding visualization, which draws attention to what is common to each pairing. This generates four candidate areas of data science expertise — activities that, although they appear on opposite ends of the pipeline, nevertheless share basic knowledge, know-how, and areas of concern.\nZone \\(IV\\) is the easiest to interpret in this way because as the pivot of the arc it is not paired. It represents the work of modeling a problem mathematically, as well as evaluating and interpreting the results of mathematical modeling. This work requires data to be available in a particular form — clean and organized, usually as “tidy” analytical tables.\nZone \\(I\\) is also relatively easy to interpret: the functions in this group each involve understanding the relationship between the pipeline and the external world, the messy interface between the enterprise of data science and the variety of real world situations in which it operates.\nWe may note in passing that \\(I\\) and \\(IV\\) can be contrasted in several ways — messy vs clean, exoteric vs esoteric, qualitative vs quantitative, existential vs essential, concrete vs abstract, etc.\nWhen it comes to zones \\(II\\) and \\(III\\), the interpretation of results is less straightforward. This is because the reality of the kind of work performed in these areas is not as clear-cut as it is for \\(I\\) and \\(IV\\). Both \\(II\\) and \\(III\\) exhibit an internal complexity not found in the others, and the two are less clearly separable from each other than they are from the other two. One reason for this complexity is that here pure and applied forms of knowledge intermingle in ways that defy easy description from an academic perspective.\nFor example, the work of “data wrangling,” often considered essential to data science, spans the two domains and involves a complex mixture of specific technological know-how and general scientific principles. It turns out that the relationship between these kinds of knowledge is highly contested, as evidenced by the reception of Donoho’s “50 Years of Data Science,” which has been criticized for separating science from engineering and demoting the importance of the latter (Donoho 2017). Regardless of the validity of this criticism, there is without doubt a long-standing conflict between data mining and data analysis over what counts as valid forms of knowledge, and this conflict emerges in the representation of zones \\(II\\) and \\(III\\) we find in our corpus.\nWe can take the conflict of interpretations over the status of technical knowledge in data science as a clue and use it to identify two broad dimensions that cross-cut the functions in zones \\(II\\) and \\(III\\): technical know-how and abstract representation. Technical know-how \\(II´\\) involves expertise in developing and deploying software and hardware designed to handle data at scale, including high-performance computing, big data architectures (such as Hadoop and its descendants), and data-oriented programming languages and libraries.\nThe topics associated with \\(II'\\) are highly specific and change rapidly relative to other forms of knowledge, and so are often omitted from, or under-represented in, academic curricula, even though to many they are the sine qua non of data science. Abstract representation \\(III´\\), on the other hand, involves expertise in areas ranging from how data are to be modeled for capture and analysis to how the results of analyses are to be presented to non-expert decision-makers. These areas of knowledge strive for formal generality over the long run; they are often expressed as grammars or design languages, frequently with visual modes (such as entity-relationship models and unified modeling language UML). They also include other forms of visualization, such as the plots developed for exploratory data analysis, such as box plots, and those used to represent statistical facts and analytical results in dashboards and infographics."
  },
  {
    "objectID": "the-four-plus-one-model.html#the-four-areas-plus-one",
    "href": "the-four-plus-one-model.html#the-four-areas-plus-one",
    "title": "The Image of the Pipeline",
    "section": "The Four Areas, Plus One",
    "text": "The Four Areas, Plus One\nWe are now ready to define and name the areas of data science expertise that emerge from an analysis of the pipeline considered as an arc. In each case, we want to identify the common context shared by the paired activities in each zone as well as the tension that exists between them by virtue of their occupying opposite sides of the pipeline. In many cases, although we can identify a shared theme in each zone’s work, the reality is that practitioners do not always interact or share disciplinary homes. One of the benefits of this model will be to identify these points of synergy and to identify new disciplinary boundaries.\nArea I: Value\nThe area of value is defined by the relationship of data science to the world from which it draws data and into which it inserts data products. More broadly, it concerns the primary motivations of data science — why do we practice data science in the first place? It combines the traditional discipline of ethics with the professional activities of business planning, policy making, developing motivations for scientific research, and other activities that have a direct impact on people and the planet. This is the area where we determine what we do versus what we do not do, in order to maximize societal and environmental benefit and minimize harm. It is also the area that looks inward to the other data science areas and provides guidance on such issues as algorithmic bias or open science. Common activities include the forming of value propositions that initiate data science projects, research into how data is created and used “in the wild,” understanding the ethics of data acquisition, manipulation, communication, and sharing, and the application of data products in the world.\nArea II´: Design\nThe area of design is defined by the relationship between human and machine forms of representation. This relationship is bidirectional: human-generated data flowing into the pipeline must be represented for machine consumption (H2M, or \\(H \\rightarrow M\\)), while analytically transformed data going out must be represented for human consumption (M2H, or \\(M \\rightarrow H\\)). This area therefore includes expertise in human-machine interaction as it appears at the points of both consuming data and producing data products. Activities here include the representation and communication of captured data for the work of analytics, e.g. in database modeling, the curation of data, and of complex data and analytical results to humans to drive decision-making and influence behavior. It also includes the making of things, with purpose (i.e. to solve problems) and intent (meaning, concision, focus). A key part of the area is the broad practice of what is often called visualization, the translation of complex quantitative information into visual (and other sensory) forms that non-experts can understand. In slightly more technical terms, the area of design focuses on what Zuboff called “informating,” the process by which the world is represented for computation and analytics, and also by which analytical models and results are represented to the world (Zuboff 1995). These two processes often produce competing representations — a private one of the world for the data scientist, and a public one for the world of the results of analytics. One task of this area is to reconcile these two representations.\nArea III´: Systems\nThe area of systems is defined by the technological infrastructure that is common to the pipeline but concentrated in the activities of wrangling data, deploying data products, and building out systems to support these activities at scale. This area includes expertise in infrastructure systems and architectures to support working with big data — big in terms of volume, velocity, and variety — and building high performance systems in both development and production environments. It includes the broad areas of hardware and software as such — computer technology as opposed to computer science. Key activities include developing cloud resources, building performant pipelines to ingest and aggregate data, developing networks of resilient distributed data, and writing and using software to accomplish tasks. This area is often referred to as “data engineering” or “machine learning engineering,” which, according to Owen, “is most of what Data Science is and Statistics is not” (Owen 2015).\nArea IV: Analytics\nThe area of analytics is defined by the practice of mathematical modeling based on data. This area includes what many consider to be the essence of data science, the combination of statistical methods with machine learning, along with information theory, optimization, network analysis, complexity theory, simulations, and other rigorous quantitative methods from a variety of fields. Although unified by a broad commitment to advanced mathematical models and computational algorithms, in reality this is a heterogeneous collection of competing schools and methods. Tensions include inference vs prediction, parametric vs non-parametric (kernel-based) methods, frequentist vs Bayesian statistics, analytic vs algorithmic solutions (including simulations), etc. Key activities include clustering, pattern recognition, regression, rule mining, feature engineering, model selection, performance evaluation, and a host of other activities. Although currently dominated by statistical methods, this area also includes the rule-based methods that dominated the field of artificial intelligence before the more recent successes of statistical learning and deep learning.\nArea V: Practice\nThe preceding four areas each represent areas of foundational knowledge, forms of expertise that can be taught as more or less separate subjects. In practice, however, these areas represent the interlocking parts of a division of labor that are integrated in the pipeline. This area consists of actual activities that brings people together to combine expertise from each of the four areas. It is characterized by data science teams working together and with external parties to develop solutions and projects that are responsible, authentic, efficient, and effective. Practice is also where the core areas of data science come into contact with a broad spectrum of domain knowledge and real world problems. The following diagram () shows the central, integrative role played by practice:\n\n\n\nThe Integrative Role of Practice"
  },
  {
    "objectID": "the-four-plus-one-model.html#two-principal-components",
    "href": "the-four-plus-one-model.html#two-principal-components",
    "title": "The Image of the Pipeline",
    "section": "Two Principal Components",
    "text": "Two Principal Components\nIs there a way to understand how the four primary areas are related to each other, beyond their being composed of functions from the same pipeline? Put another way, does the pipeline-as-arc model exhibit any structural features that will help us conceptualize the broader space of data science? Two such features stand out: (1) the opposition between concrete and abstract forms of representation, and (2) between human and machine processing.\nRegarding the concrete and the abstract, it’s clear that the arc model has a metric quality to it: as one moves toward the pivot point of analysis, one moves away from the concrete messiness of reality as experienced to the “tidy” and abstract world of mathematics; similarly, as one moves from the pivot back to the world, there is a requirement to convert esoteric results into more humanly intelligible forms, often through a process of concretization; visualizations succeed by employing concrete metaphors that flesh out mathematical ideas that are notoriously detached from the imagination — no one can imagine, for example, n-dimensional spaces beyond a handful of dimensions. The arc describes a dialectic of abstraction and concretization that defines the ebb and flow and data science work.\n\n\n\nThe Four Areas in Two Dimensions\n\n\nThe dimension of human and machine processing exhibits a similar duality, that between the conversion of information from humanly accessible forms, such as given by data acquired by instruments, into machine readable and processible forms, and the reverse. The process of moving from human to machine representations is a large part of what data capture, modeling, and wrangling is all about, while the process of converting the results of machine learning, broadly conceived, into humanly actionable form is what visualization and productization are all about. The reality of this dualism is captured by the concept of human-computer interaction (HCI), an established field that is applicable to both sides of the arc.\nHow do the four fundamental areas map onto these two dimensions? We can define each area as a combination of one pole from each duality; the four areas result from all possible permutations of the two dimensions. This produces the following high level characterizations of each area: (1) Value is concerned with concrete humanity, (2) Design with abstract humanity, (3) Analytics with abstract machinery, and (4) Systems is concerned with concrete machinery. All of these make intuitive sense, with the exception of Design. This is consistent, however, with the fact that the area of Design emerges from this analysis as an undervalued and not well understood area of expertise, even though Yau emphasized it early on (Yau 2009b). Indeed, one of the consequences of this analysis is to train our attention on this area of knowledge and to develop it further.\nOne exciting interpretation of the two dimensions defined here is that they correspond to two principal components that undergird the general field of data science. As components, these axes define two orthogonal dimensions within which all the specific topics of data science may, in principle, be plotted. The reality behind these axes may be that they represent cognitive styles associated with the division of labor implied by the data science pipeline.\nPC1: Human versus Machine\nThe human-machine axis accounts for the most variance in the field. This seems evident from the fact that Conway’s Venn diagram model of data science represents only the machine side of our model, with practice replaced by “substantive expertise” (Conway 2010). The human side — Value and Design — is left out, or short-changed by being lumped in with domain knowledge. The very fact that the human side has to be explained and added to the model suggests strongly that it defines a pole at some distance from the areas of knowledge described in Conway’s model. The human pole refers to humanity understood as situated in their historical, social, and cultural milieu. It is synonymous with human experience. The machine pole refers to the technoscientific apparatus of formal, quantitative reasoning that operates on representations of the human and the world. In the context of data science, it is more or less synonymous with machine intelligence, broadly conceived to include machine learning but also other modes of analysis on the spectrum of prediction and inference. Given these poles, the human-machine axis represents the opposition between humanistic disciplines that seek to understand human experience as such, and the formal sciences that employ machine intelligence, broadly conceived, to interpret that experience as represented and aggregated in the form of data.\nPC2: Concrete versus Abstract\nThe abstract-concrete axis accounts for the difference between two forms of knowledge, roughly between direct experience and the indirect representation of that experience enabled through data. Both the realm of Value and Systems involve immersion in the messy details of lived experience — and direct acquaintance with the devils in those details. This is the messy world of hacks and ironies. The realms of Design and Analysis, on the other hand, are founded on abstract representations that strive for clear and distinct purity, and which allow for deductive reasoning to succeed at the cost of simplifying assumptions and reduced representations. This is the orderly world of models. The concrete pole refers to situated knowledge, knowledge as understood by hackers and makers, but also ethnographers who seek to maximize thick description in their work. It represents concrete materiality. The abstract pole refers to formal knowledge, knowledge in the form of mathematical symbolism, deductive proofs, and algorithmic patterns. It is abstract form. Given these poles, the concrete-abstract axis is roughly the opposition between applied and pure forms of knowledge, between those that embrace materiality and those that seek purity of form."
  },
  {
    "objectID": "the-four-plus-one-model.html#final-representation",
    "href": "the-four-plus-one-model.html#final-representation",
    "title": "The Image of the Pipeline",
    "section": "Final Representation",
    "text": "Final Representation\nThe result of the preceding may be represented by the following graphic.\n\n\n\nThe 4+1 Model of Data Science\n\n\nThis visualization represents data science as composed of specific and complementary forms of knowledge. The vertical axis defines the dominant polarity between analysis — the how of data science, often identified entirely with it, contrasted with the why of data science, from which data science derives its meaning and value as a profession. The horizontal access defines the polarity of methods that are often obscured in academic definitions of data science — the supporting practices that make the Analytics component work in the first place."
  },
  {
    "objectID": "the-four-plus-one-model.html#references",
    "href": "the-four-plus-one-model.html#references",
    "title": "The Image of the Pipeline",
    "section": "References",
    "text": "References\n\n\nConway, Drew. 2010. “The Data Science Venn Diagram.” http://drewconway.com/zia/2013/3/26/the-data-science-venn-diagram.\n\n\nDonoho, David. 2017. “50 Years of Data Science.” Journal of Computational and Graphical Statistics 26 (4): 745–66. https://doi.org/10.1080/10618600.2017.1384734.\n\n\nHayashi, Chikio. 1998. Data Science, Classification, and Related Methods: Proceedings of the Fifth Conference of the International Federation of Classification Societies (IFCS-96), Kobe, Japan, March 27-30, 1996. Kobe, Japan: Springer.\n\n\nMason, Hilary, and Christopher Wiggins. 2010. “A Taxonomy of Data Science.” http://www.dataists.com/2010/09/a-taxonomy-of-data-science/.\n\n\nOwen, Sean. 2015. “What “50 Years of Data Science” Leaves Out.” https://medium.com/@srowen/what-50-years-of-data-science-leaves-out-2366c9b61d3d.\n\n\nWirth, Rüdiger, and Jochen Hipp. 1999. “CRISP-DM: Towards a Standard Process Model for Data Mining.” https://www.semanticscholar.org/paper/Crisp-dm%3A-towards-a-standard-process-modell-for-Wirth-Hipp/48b9293cfd4297f855867ca278f7069abc6a9c24.\n\n\nZuboff, Shoshana. 1995. In the Age of the Smart Machine: The Future of Work and Power. [Repr.]. Basic Books. http://gen.lib.rus.ec/book/index.php?md5=76dd1180c201eed5973bf83d45489b37."
  },
  {
    "objectID": "concluding-remarks.html",
    "href": "concluding-remarks.html",
    "title": "Concluding Remarks",
    "section": "",
    "text": "The point of the 4 + 1 model, abstract as it is, is to provide a practical template for strategically planning the various elements of a school of data science. To serve as an effective template, a model must be general. But generality if often purchased at the cost of intuitive understanding. The following caveats may help make sense of the model when considering its usefulness when applied to various concrete activities.\nThe model describes areas of academic expertise, not objective reality. It is a map of a division of labor writ large. Although each of the areas has clear connections to the others, the question to ask when deciding where an activity belongs is: who would be an expert at doing it? The realms help refine this question: the analytics area, for example, contains people who are good at working with abstract machinery. The four areas have the virtue of isolating intuitively correct communities of expertise. For example, people who are great at data product design may not know the esoteric depths of machine learning, and that adepts at machine learning are not usually experts in understanding human society and normative culture.\nEach area in the model contains a collection of subfields that need to be teased out. Some areas will have more subfields than others. Although some areas may be smaller than others in terms of number of experts (faculty) and courses, each area has a major impact on the overall practice of data science and the quality of an academic program’s activities. In addition, these subfields are in an important sense “more real” than the categories. We can imagine them forming a dense network in which the areas define communities with centroids, and which are more interconnected than the clean-cut image of the model implies.\nThe principal components abstract/concrete and human/machine are meant to help imagine the kinds of activities that belong in each area, through their connotations when combined to form the four bigrams — concrete human, abstract human, concrete machine, and abstract machine. For example, the area of value as the realm of the “concrete human” (or perhaps “concrete humanity”) is meant to connote what the Spanish philosopher Unamuno called the world of “flesh and bone” within which we live and die, that is, where things matter. On the other hand, analytics as the realm of the “abstract machine” is meant to connote the platonic world of mathematical reasoning which, since Euclid, has been characterized by rigorous, abstract, deductive reasoning that has literally been described as an abstract machine (see Alan Turing).\nAt the center of this model and each area is people. Even in the area classified as “abstract machine,” people and human thinking is at the center."
  },
  {
    "objectID": "appendix-sources.html",
    "href": "appendix-sources.html",
    "title": "Appendix A — Primary Sources",
    "section": "",
    "text": "About the Sources\nThe primary sources on which the conclusions of this essay are based comprise a variety of documents, from technical journals to blog posts to internal reports. They also come from a range of viewpoints, from data analysis and statistics to data mining and data science per se. For the purposes of the essay, we select a more or less representative subset across these axes of variation. With respect to representativeness, in some cases a document was chosen for its influence, in others, such as the post by Dataman, because it is considered more or less typical of common genre.\nThe twelve documents chosen are listed in chronological order, beginning with Tukey’s seminal essay on data analysis and ending with contempory explainers. Included also are the definitions of the CRISP-DM and KDD processes which are the most developed pipeline models.\nEach source entry below contains short description and then list the phases cited by the authors as fundamental to data processing, broadly conceived. We then map these phases onto the standard sequence described in the main part of this essay and listed here for convenience.\nThese mappings are indicated by an arrow pointing to the subset of terms from the standard sequence, e.g. … \\(\\rightarrow [Explore]\\) These mappings are also aggregated into a composite pipeline and displayed the table below;each model row is referenced by its key as defined in the entries.\nIt should be noted that in most cases these phases are explicitly described as a process and often as a pipeline. When they are not, the implication is strong. In some cases, the process is likened to a cycle, emphasizing the connection between the endpoints of the pipeline, which is also emphasized by the 4+1 model."
  },
  {
    "objectID": "appendix-sources.html#source-list",
    "href": "appendix-sources.html#source-list",
    "title": "Appendix A — Primary Sources",
    "section": "Source List",
    "text": "Source List\n\nTukey on Data Analysis\nKey: Tukey\nYear: 1962\nSource: Tukey (1962) URL\nField: Statistics, Data Analysis\nIn this classic essay, Tukey introduces the concept of data analysis, which he distinguishes from mathematical statistics and likens to an empirical science. He defines data analysis as an empirical process with phases including “… procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data” (p. 2). Unpacking this statement yields a four phase model.\n\nPlanning: This phase includes “ways of planning the the gather of data to make its analysis easier.” \\(\\rightarrow [Plan]\\)\nGathering: The gathering of data, either through creation or by acquisition of “data already obtained” (p. 40). Includes also the shaping of data “to make its analysis easier,” which corresponds to our concept of Preparation. \\(\\rightarrow [Collect]\\)\nAnalyzing: This is where data are analyzed with “all the machinery and results of (mathematical) statistics.” \\(\\rightarrow [Explore, Model]\\)\nInterpreting: “techniques for interpreting the results of” analysis. \\(\\rightarrow [Interpret]\\)\n\nNote that Tukey’s model is unique in that his concept of exploration carries much more weight than how the term tends to be used to day.\n\n\nFayyad on KDD\nKey: KDD\nYear: 1996 Source: Fayyad et al. (1996) URL→\nField: Data Mining\n\nKDD, or Knowledge Discovery in Databases, emerged in the late 1980s as both datasets and the computational resources to work with them became abundant. These resources included commercial databases and the PC. In many ways the most adjacent field to contemoporary data science, this approach is unabashedly dedicated to finding patterns in data prior to developing a probabilistic model to justify their use. Fayyad’s essay identifies five steps (Fayyad et al. 1996: 84). He emphasizes the highly iterative and cyclical nature of the process, arguing that it “may contain loops between any two steps.” Another significant aspect of this conception of the pipeline is the role of exploration in the analytical phase: “Data Mining is a step in the KDD process consisting of applying data analysis and discovery algorithms that, under acceptable computational efficiency limitations, produce a particular enumeration of patterns over the data ….” (p. 83)\n\nSelection: Creating a target data set, or focusing on a subset of variables or data samples, on which discovery is to be performed. \\(\\rightarrow [Collect]\\)\nPre-processing: Cleaning and pre processing the data in order to obtain consistent data. \\(\\rightarrow [Clean]\\)\nTransformation: Transformation of the data using dimensionality reduction and other methods. \\(\\rightarrow [Prepare]\\)\nData Mining: Searching for patterns of interest in a particular representational form, depending on the DM objective (usually, prediction). \\(\\rightarrow [Model]\\)\nInterpretation/Evaluation: Interpretation and evaluation of the mined patterns. \\(\\rightarrow [Interpretl]\\)\n\n\n\nAzevedo on SEMMA\nKey: SEMMA\nYear: 1996 Source: Azevedo and Santos (2008)\nField: Statistics\nThe SEMMA model was developed the by SAS institute in 1996 as part of the documentation for their product, SAS Enterprise Miner. Even so, the model is referenced outside of this context, often as a comparison to KDD and CRISP-DM. Its bias towards statististics is evident in the first step.\n\nSample: Sampling the data by extracting a portion of a large data set big enough to contain the significant information, yet small enough to manipulate quickly. \\(\\rightarrow [Collect]\\)\nExplore: Exploration of the data by searching for unanticipated trends and anomalies in order to gain understanding and ideas \\(\\rightarrow [Explore]\\)\nModify: Modification of the data by creating, selecting, and transforming the variables to focus the model selection process \\(\\rightarrow [Prepare]\\)\nModel: Modeling the data by allowing the software to search automatically for a combination of data that reliably predicts a desired outcome. \\(\\rightarrow [Model]\\)\nAssess: Assessing the data by evaluating the usefulness and reliability of the findings from the DM process and estimate how well it performs. \\(\\rightarrow [Interpret]\\)\n\n\n\nHayashi on Data Science\nKey: Hayashi   Year: 1998\nSource: Hayashi et al. (1998) URL→\nField: Statistics\nThe Japanese statistician Chikio Hayashi adopted the term “data science” in the early 1990s to define a field that did not succumb to what he saw to be the errors of both statistics and data analysis. He argued that mathematical statistics had become too attached to problems of inference and removed from reality, while data analysis had lost interest in understanding the meaning of the data it deals with. His definition of data science is decidely processual: “Data Science consists of three phases: design for data, collection of data and analysis on data. It is important that the three phases are treated with the concept of unification based on the fundamental philosophy of science …. In these phases the methods which are fitted for the object and are valid, must be studied with a good perspective.” (p. 41) Similar to KDD and CRISM-PM, Hayashi envisioned this process as a spiral, oscillating between poles if what he called “diversification” and “simplification.” Note also that each of these terms are broad; each, as described, comprises more than on of the standard sequence phases.\n\nDesign: Surveys and experiments are developed to capture data from “multifarious phenomena.” \\(\\rightarrow [Understand, Plan]\\)\nCollection: Phenomena are expressed as multidimensional or time-series data; properties of the data are made clear. At this stage, data are too complicated to draw clear conclusions. (Representation) \\(\\rightarrow [Collect, Explore, Prepare]\\)\nAnalysis: By methods of classification, multidimensional data analysis, and statistics, data structure is revealed. Simplification and conceptualization. Also yields understanding of deviations of the model, which begins the cycle anew. (Revelation) \\(\\rightarrow [Model, Interpet]\\)\n\n\n\nWirth and Hipp on CRISP-DM\nKey: CRISPDM\nSource: Wirth and Hipp (1999) URL→\nField: Data Mining\nNotes:\n\n“At the top level, the data mining process is organized into a small number of phases. Each phase consists of several second-level generic tasks.”\nThe process is cyclic and recursive.\n\nSteps:\n\nBusiness Understanding: Understanding project objectives and requirements from a business perspective. Development of a plan.\nData Understanding: Initial data collection and activities to get familiar with the data, e.g. to identify data quality problems, to discover first insights into the data, or to detect interesting subsets to form hypotheses for hidden information. This is really two phases, which are combined because of their close relationship: Collection and Exploration.\nData Preparation: Construction of the final dataset. Tasks include table, record, an attribute selection, data cleaning, construction of new attributes, and transformation of data for modeling tools.\nModeling: Modeling techniques selected and applied, parameters calibrated.\nEvaluation At this stage in the project you have built one or more models that appear to have high quality, from a data analysis perspective. Before proceeding to final deployment of the model, it is important to more thoroughly evaluate the model, and review the steps executed to construct the model, to be certain it properly achieves the business objectives. A key objective is to determine if there is some important business issue that has not been sufficiently considered. At the end of this phase, a decision on the use of the data mining results should be reached.\nDeployment: Creation of the model is generally not the end of the project. Usually, the knowledge gained will need to be organized and presented in a way that the customer can use it. Depending on the requirements, the deployment phase can be as simple as generating a report or as complex as implementing a repeatable data mining process. In many cases it will be the user, not the data analyst, who will carry out the deployment steps. In any case, it is important to understand up front what actions will need to be carried out in order to actually make use of the created models.\n\n\n\nMason and Wiggins on OSEMI\nKey: OSEMI Source: Mason and Wiggins (2010) URL→\nField: Data Science\nNotes: * Assumes context of web, available data. * Borrowed language from 5 Steps of a Data Science Project Lifecycle.\nSteps:\n\nObtain: Gather data from relevant sources through APIs, web scraping, etc.\nScrub: Clean data and convert to machine readable formats. Clearning includes handling missing data, inconsistent labels, or awkward formatting; stripping extraneous characters; normalizing values, etc.\nExplore: Find significan patterns and trends using statistical and data analytic methods, These include visualizing, clustering, performing dimensionality reduction.\nModel: Construct methods to predict and forecast.\nInterpret: Put the results to good use.\n\n\n\nOjeda, et al. on Data Science\nKey: Ojeda+ Source: Ojeda et al. (2014) URL→\nField: Data Science\n\nAcquisition: The first step in the pipeline is to acquire the data from a variety of sources, including relational databases, NoSQL and document stores, web scraping, and distributed databases such as HDFS on a Hadoop platform, RESTful APIs, flat files, and hopefully this is not the case, PDFs.\nExploration and understanding: The second step is to come to an understanding of the data that you will use and how it was collected; this often requires significant exploration.\nMunging, wrangling, and manipulation: This step is often the single most time-consuming and important step in the pipeline. Data is almost never in the needed form for the desired analysis.\nAnalysis and modeling: This is the fun part where the data scientist gets to explore the statistical relationships between the variables in the data and pulls out his or her bag of machine learning tricks to cluster, categorize, or classify the data and create predictive models to see into the future.\nCommunicating and operationalizing: At the end of the pipeline, we need to give the data back in a compelling form and structure, sometimes to ourselves to inform the next iteration, and sometimes to a completely different audience. The data products produced can be a simple one-off report or a scalable web product that will be used interactively by millions.\n\n\n\nCaffo, et al. on Data Science\nKey: Caffo+ Source: Caffo, Peng, and Leek (2015) URL→\nField: Data Science\n\nQuestion\n\nGet\n\nExplore\n\nModel\n\nInterpret\n\nCommunicate\n\n\n\nDonaho on Data Science\nKey: Donoho Source: Donoho (2017) URL→\nField: Statistics\n\nGather\nPrepare\nExplore\nRepresent and transform\nCompute\nModel\nPresent\nMeta\n\n\n\nGéron on Machine Learning\nKey: Géron Source: Géron (2017) URL→\nField: Data Science\n\nBig picture\n\nGet\n\nClean\n\nDiscover\nPrepare Model\nFine tune\n\nLaunch\n\n\n\nDas on Data Science\nKey: Das Source: Das (2019) URL→\nField: Data Science\n\nUnderstand\nMine\nClean\nExplore\nFeatures\nModel\nVisualize\n\n\n\nDataman on Data Science\nKey: Dataman Source: Dataman (2020) URL→\nField: Data Science\n\nBusiness\nData requirements\n\nCollection\nEDA\nModeling\nEvaluation\nDeployment\nMonitoring\n\n\n\nPorter on Data Science\nKey: Porter Source: Porter (2020) Field: Statistics \n\nCollect\n\nStore and represent\n\nManipulation\n\nComputing\n\nAnalytics\n\nCommunicate\n\nPractice\nDisciplinary"
  },
  {
    "objectID": "appendix-sources.html#summary-table",
    "href": "appendix-sources.html#summary-table",
    "title": "Appendix A — Primary Sources",
    "section": "Summary Table",
    "text": "Summary Table\n\n\n\n\n\n\n  \n    \n      \n      Understand\n      Plan\n      Collect\n      Store\n      Clean\n      Explore\n      Prepare\n      Model\n      Interpret\n      Communicate\n      Deploy\n      Reflect\n    \n  \n  \n    \n      Tukey\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      KDD\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      SEMMA\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      Hayashi\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      CRISPDM\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      OSEMI\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      Ojeda+\n      (collection)\n      collection\n      \n      \n      collection\n      analysis\n      analysis\n      design\n      collection\n      \n      collection\n      design\n    \n    \n      Caffo+\n      pre-processing\n      selection\n      \n      \n      \n      interpretation and evaluation\n      data mining\n      \n      transformation\n      \n      \n      \n    \n    \n      Donoho\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      Géron\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      Das\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    \n    \n      Dataman\n      \n      sample\n      \n      \n      explore\n      assess\n      model\n      \n      modify\n      \n      \n      \n    \n    \n      Porter\n      \n      gathering\n      \n      \n      analyzing\n      interpret\n      analyzing\n      planning\n      gathering"
  },
  {
    "objectID": "appendix-sources.html#extra",
    "href": "appendix-sources.html#extra",
    "title": "Appendix A — Primary Sources",
    "section": "Extra",
    "text": "Extra"
  },
  {
    "objectID": "appendix-sources.html#references",
    "href": "appendix-sources.html#references",
    "title": "Appendix A — Primary Sources",
    "section": "References",
    "text": "References\n\n\nAzevedo, Ana Isabel Rojão Lourenço, and Manuel Filipe Santos. 2008. “KDD, SEMMA and CRISP-DM: A Parallel Overview.” IADS-DM.\n\n\nCaffo, Brian, Roger D. Peng, and Jeffrey Leek. 2015. Executive Data Science. Leanpub.\n\n\nDas, Sangeet Moy. 2019. “Data Science Life Cycle 101 for Dummies Like Me.” Medium. https://towardsdatascience.com/data-science-life-cycle-101-for-dummies-like-me-e66b47ad8d8f.\n\n\nDataman, Dr. 2020. “Data Science Modeling Process & Six Consultative Roles.” Medium. https://towardsdatascience.com/data-science-modeling-process-fa6e8e45bf02.\n\n\nDonoho, David. 2017. “50 Years of Data Science.” Journal of Computational and Graphical Statistics 26 (4): 745–66. https://doi.org/10.1080/10618600.2017.1384734.\n\n\nFayyad, Usama M, Gregory Piatetsky-Shapiro, Padhraic Smyth, et al. 1996. “Knowledge Discovery and Data Mining: Towards a Unifying Framework.” In KDD, 96:82–88.\n\n\nGéron, Aurélien. 2017. Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems. 1 edition. Beijing ; Boston: O’Reilly Media.\n\n\nHayashi, Chikio, Keiji Yajima, Hans H. Bock, Noboru Ohsumi, Yutaka Tanaka, and Yasumasa Baba, eds. 1998. Data Science, Classification, and Related Methods: Proceedings of the Fifth Conference of the International Federation of Classification Societies (IFCS-96), Kobe, Japan, March 27, 1996. Studies in Classification, Data Analysis, and Knowledge Organization. Springer Japan. https://doi.org/10.1007/978-4-431-65950-1.\n\n\nMason, Hilary, and Christopher Wiggins. 2010. “A Taxonomy of Data Science.” Dataists.\n\n\nOjeda, Tony, Sean Patrick Murphy, Benjamin Bengfort, and Abhijit Dasgupta. 2014. Practical Data Science Cookbook. Packt Publishing Ltd.\n\n\nPorter, Michael D. 2020. “A Framework for Data Science.”\n\n\nTukey, John W. 1962. “The Future of Data Analysis.” The Annals of Mathematical Statistics 33 (1): 1–67.\n\n\nWirth, Rüdiger, and Jochen Hipp. 1999. “CRISP-DM: Towards a Standard Process Model for Data Mining.”"
  },
  {
    "objectID": "appendix-sources.html#test-html",
    "href": "appendix-sources.html#test-html",
    "title": "Appendix A — Primary Sources",
    "section": "Test HTML",
    "text": "Test HTML"
  },
  {
    "objectID": "ds-and-ai.html",
    "href": "ds-and-ai.html",
    "title": "Appendix B — Relation to AI",
    "section": "",
    "text": "The four areas of data science defined here are surprisingly analogous to the four approaches to artificial intelligence defined by Russel and Norvig in their classic textbook on the subject (Russell and Norvig 1995: 5). Their four part model was generated by combining the axes thinking/acting with human/rational as follows:\n\n\n\nbehavior\nmode\nsystems\n\n\n\n\nthinking\nhumanly\ncognitive models, ontologies\n\n\nthinking\nrationally\nlogic, laws of thought\n\n\nacting\nhumanly\nTuring test, situated action\n\n\nacting\nrationally\nagents, bots\n\n\n\nNow, it is easy to see how the following analogies make sense:\n\\[\nabstract : concrete :: thinking : action\n\\]\nand\n\\[\nhuman : rational :: human : machine\n\\]\nSo it makes sense to compare the above table with this one for data science:\n\n\n\n\n\n\n\n\n\nlevel\nfocus\narea\ntopic\n\n\n\n\nabstract\nhuman\ndesign\nontologies, data models, visualizations\n\n\nabstract\nmachine\nanalytics\nmath, logic, algorithms\n\n\nconcrete\nhuman\nvalue\nethics, research questions, value propositions\n\n\nconcrete\nmachine\nsystems\nhardware, software, security\n\n\n\nBy comparing last columns of each table we can see that the 4+1 model of data science and Russell and Norvig’s model of artificial intelligence share the same space. The difference that the former defines kinds of acquired knowledge, whereas the latter concerns kinds of built systems.\nReferences\n\n\nRussell, Stuart Jonathan, and Peter Norvig. 1995. Artificial Intelligence: A Modern Approach. Prentice Hall."
  }
]